{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import trange\n",
    "import random\n",
    "\n",
    "import scipy.io\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2214f",
   "metadata": {},
   "source": [
    "# Image Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433bac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_images ( dataset_path, indices , id_test , ids , labels ) :\n",
    "    \n",
    "    label = (ids[id_test] - 1) // 80\n",
    "\n",
    "    name = dataset_path + '/jpg/' + str(label) + '/image_' + str(ids[id_test]).zfill(4) + '.jpg'\n",
    "    image = Image.open( name )\n",
    "    \n",
    "    top = 0\n",
    "    show_image_label(top, image, labels[id_test], ids[id_test] )\n",
    "    \n",
    "    accuracy = 0\n",
    "    \n",
    "    for i in indices[0] :\n",
    "        label_i = labels[i]\n",
    "        name = dataset_path + '/jpg/' + str(label_i) + '/image_' + str(ids[i]).zfill(4) + '.jpg'\n",
    "\n",
    "        image = Image.open( name )\n",
    "\n",
    "        show_image_label(top, image, label_i, ids[i] )   \n",
    "        top = top + 1\n",
    "        \n",
    "    \n",
    "def show_image_label ( top, image, label , image_id ) :\n",
    "    \n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(image, aspect='auto')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{top} - Image id {image_id} with label {label}.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4101d4",
   "metadata": {},
   "source": [
    "# Generate descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5ddd8-54fe-4270-9760-304e722e79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_descriptors (image, model, my_transform, my_device='cpu') :\n",
    "\n",
    "    model_input = my_transform(image) \n",
    "    model_input = model_input.unsqueeze_(0)\n",
    "    \n",
    "    model = model.to(my_device)\n",
    "    model_input = model_input.to(my_device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        desc_deep = model(model_input).squeeze(0)\n",
    "    \n",
    "    return desc_deep.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af33191",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff15234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_dataset( dataset_path, model, my_transform, my_device ) :\n",
    "\n",
    "    mat = scipy.io.loadmat( dataset_path+'/datasplits.mat' )\n",
    "\n",
    "    ids = mat['tst1'][0] #  'tst1' or 'trn1' or 'val1' \n",
    "    \n",
    "    space = []\n",
    "    labels = []\n",
    "    \n",
    "    for id in tqdm.tqdm(ids, desc='Processing test set') :\n",
    "\n",
    "        label = (id - 1) // 80\n",
    "        name = dataset_path + '/jpg/' + str(label) + '/image_' + str(id).zfill(4) + '.jpg'\n",
    "\n",
    "        image = Image.open( name )\n",
    "        \n",
    "        if image is None:\n",
    "            print(f'Reading image Error. Path: {name}')\n",
    "            return None\n",
    "\n",
    "        desc_deep = create_deep_descriptors(image, model, my_transform, my_device)\n",
    "\n",
    "        space.append(desc_deep)\n",
    "        labels.append(label)\n",
    "        \n",
    "    print( ' -> [I] Space Describing Info:\\n', \n",
    "        '\\nNumber of images: ', len(space), \n",
    "        '\\nNumber of labels: ', len(labels),\n",
    "        '\\nDimension: ', len(space[0])\n",
    "        )\n",
    "\n",
    "    return space , labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42375af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def run_test ( space , labels , dataset_path, model, my_transform, my_device, top=10 ) :\n",
    "    knn = NearestNeighbors(n_neighbors=top+1).fit(space)\n",
    "    \n",
    "    mat = scipy.io.loadmat( dataset_path+'/datasplits.mat' )\n",
    "\n",
    "    ids = mat['tst1'][0] #  'tst1' or 'trn1' or 'val1'\n",
    "    \n",
    "    accuracy_t = 0\n",
    "    \n",
    "    for id_test in tqdm.tqdm(ids, desc='running the test phase') :\n",
    "        \n",
    "        label = (id_test - 1) // 80\n",
    "        name = dataset_path + '/jpg/' + str(label) + '/image_' + str(id_test).zfill(4) + '.jpg'\n",
    "\n",
    "        image = Image.open( name )\n",
    "        \n",
    "        desc_deep = create_deep_descriptors(image, model, my_transform, my_device)\n",
    "\n",
    "        indices = knn.kneighbors(desc_deep.reshape(1, -1))[1]\n",
    "\n",
    "        labels_top = [ labels[i] for i in indices[0] ]\n",
    "\n",
    "        accuracy = sum( np.equal(labels_top, label) )\n",
    "        accuracy =( (accuracy-1)/(top) ) * 100\n",
    "        accuracy_t = accuracy_t + accuracy\n",
    "        \n",
    "    print(f'Average accuracy in the test set: {accuracy_t/len(ids):5.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b8b6e",
   "metadata": {},
   "source": [
    "# Experimental evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_single_image ( space , labels , dataset_path, model, my_transform, my_device, top=10 ) :\n",
    "    knn = NearestNeighbors(n_neighbors=top+1).fit(space)\n",
    "    \n",
    "    mat = scipy.io.loadmat( dataset_path+'/datasplits.mat' )\n",
    "\n",
    "    ids = mat['tst1'][0] #  'trn1' or 'val1'\n",
    "    \n",
    "    id_test = random.randrange( len(ids) )\n",
    "        \n",
    "    label = (ids[id_test] - 1) // 80\n",
    "    name = dataset_path + '/jpg/' + str(label) + '/image_' + str(ids[id_test]).zfill(4) + '.jpg'\n",
    "    \n",
    "    image = Image.open( name )\n",
    "    \n",
    "    if image is None:\n",
    "        print(f'Reading image Error. Path: {name}')\n",
    "        return None\n",
    "\n",
    "    desc_deep = create_deep_descriptors(image, model, my_transform, my_device)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(desc_deep.reshape(1, -1))\n",
    "    \n",
    "    show_top_images(dataset_path, indices, id_test, ids, labels)\n",
    "    \n",
    "    labels_top = [ int(labels[i]) for i in indices[0] ]\n",
    "    \n",
    "    accuracy = sum( np.equal( label , labels_top ) )\n",
    "    accuracy =( (accuracy-1)/(top) ) * 100 \n",
    "    \n",
    "    print(f'Accuracy for image id {ids[id_test]}: {accuracy:5.2f}%')\n",
    "    \n",
    "    print(name)    \n",
    "    print(f'Image: {ids[id_test]} with label {labels[id_test]}')    \n",
    "    print(f'Closest image: {ids[indices[0][0]]} with distance {distances[0][0]} and label {labels[indices[0][0]]}')\n",
    "    print('Distances: ',distances)\n",
    "    print('Indices: ',indices[0])\n",
    "    print('Labels: ',labels_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939449e",
   "metadata": {},
   "source": [
    "# Create the Descriptor model and load weights \n",
    "\n",
    "\n",
    "Aqui vocês devem:\n",
    "1. Criar o modelo descritor que é uma arquitetura CNN sem a última camada da FC de classificação. Atribua a variável `model_descriptor`.\n",
    "2. Criar o objeto que indica quais são as transformações necessárias para o modelo. Atribua a variável `my_transform`.\n",
    "3. Definir se os modelos vão executar na CPU ou na GPU. Atribua a variável `my_device`.\n",
    "4. Faça o teste com pelo menos 3 arquiteturas diferentes e reporte o resultado da função `run_test` em formato de tabela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817fc9f-1bc0-4b9b-aaba-b4a884e91409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "973dcb7d-2338-4cf6-904f-577948db3512",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fbc66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = # ********* INSERT HERE THE Flowers-17 DATASET PATH ******************\n",
    "\n",
    "# Using model descriptor, represent all images in the testing split of the dataset. \n",
    "space, labels = represent_dataset ( dataset_path , model_descriptor, my_transform, my_device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a0c8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each image of the testing split of the dataset, use the image as the query\n",
    "# for the image retrieval problem, i.e., describe the image using the model descriptor, \n",
    "# and search for the k closest descriptors of the images in the testing split dataset. \n",
    "# After that, measure the accuracy of the image retrieval by counting how many of the k\n",
    "# retrieved images has the same label of the query image, and divide it by k. \n",
    "# This result will be the accuracy of the image retrieval result for that specific image. \n",
    "# Repeat it for each image of the testing split of the dataset and compute the average of \n",
    "# all calculated accuracies.\n",
    "\n",
    "run_test( space, labels, dataset_path, model_descriptor, my_transform, my_device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305bba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a random image of the testing split of the dataset, use the image as the query\n",
    "# for the image retrieval problem, i.e., describe the image using the model descriptor, \n",
    "# and search for the k closest descriptors of the images in the testing split dataset. \n",
    "# After that, measure the accuracy of the image retrieval by counting how many of the k\n",
    "# retrieved images has the same label of the query image, and divide it by k. \n",
    "# This result will be the accuracy of the image retrieval result for that specific image.\n",
    "# Also display the query image, and all k images returned by the image retrieval problem.\n",
    "# For each returned image, also display its class, and the Euclidean distance between its\n",
    "# descriptor and the descriptor of the query image.\n",
    "# Since the query image also is in the testing split of the dataset, it is expected that \n",
    "# the first returned image is the query image itself, and the distance between the \n",
    "# descriptors to be zero.\n",
    "\n",
    "retrieve_single_image( space, labels, dataset_path, model_descriptor, my_transform, my_device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
